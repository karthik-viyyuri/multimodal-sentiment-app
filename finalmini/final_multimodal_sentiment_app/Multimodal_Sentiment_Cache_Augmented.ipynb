{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c670eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.13.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu sentence-transformers transformers scikit-learn pandas numpy pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3addf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.3)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.13.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers transformers pillow tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4280c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /opt/anaconda3/lib/python3.12/site-packages (0.115.8)\n",
      "Requirement already satisfied: uvicorn in /opt/anaconda3/lib/python3.12/site-packages (0.34.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/lib/python3.12/site-packages (0.0.20)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /opt/anaconda3/lib/python3.12/site-packages (from fastapi) (0.45.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from fastapi) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from fastapi) (4.13.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from starlette<0.46.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn python-multipart pillow sentence-transformers transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad55ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import faiss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd6a2c",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570db2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessing complete. Saved as 'cleaned_combined_text_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load CSVs\n",
    "twitter_df = pd.read_csv(\"/Users/karthikviyyuri/Documents/finalmini/datasets/twitter and reddit/Twitter_Data.csv\")\n",
    "reddit_df = pd.read_csv(\"/Users/karthikviyyuri/Documents/finalmini/datasets/twitter and reddit/Reddit_Data.csv\")\n",
    "\n",
    "# Rename columns for uniformity\n",
    "twitter_df = twitter_df.rename(columns={\"clean_text\": \"text\", \"category\": \"label\"})\n",
    "reddit_df = reddit_df.rename(columns={\"clean_comment\": \"text\", \"category\": \"label\"})\n",
    "\n",
    "# Clean text (for Reddit)\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)                  # remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)              # remove non-alphabet characters\n",
    "    return text.lower().strip()\n",
    "\n",
    "reddit_df['text'] = reddit_df['text'].apply(clean_text)\n",
    "\n",
    "# Remove NaN or invalid labels\n",
    "twitter_df = twitter_df.dropna(subset=[\"label\"])\n",
    "reddit_df = reddit_df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Convert labels to int\n",
    "twitter_df['label'] = twitter_df['label'].astype(int)\n",
    "reddit_df['label'] = reddit_df['label'].astype(int)\n",
    "\n",
    "# Combine both datasets\n",
    "combined_df = pd.concat([twitter_df, reddit_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the data (optional)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save or return\n",
    "combined_df.to_csv(\"/Users/karthikviyyuri/Documents/finalmini/datasets/text_dataset.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete. Saved as 'cleaned_combined_text_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859219ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative/1.jpg</td>\n",
       "      <td>how i feel today legday jelly aching gym</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative/10.jpg</td>\n",
       "      <td>arrivatw absolute disgrace two carriages from ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive/100.jpg</td>\n",
       "      <td>this is my valentines from  of my nephews i am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral/1000.jpg</td>\n",
       "      <td>betterfeelingfilms rt via instagram first day ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive/1001.jpg</td>\n",
       "      <td>zoes first love rattled johnnyharper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_path                                         clean_text  label\n",
       "0     negative/1.jpg           how i feel today legday jelly aching gym     -1\n",
       "1    negative/10.jpg  arrivatw absolute disgrace two carriages from ...     -1\n",
       "2   positive/100.jpg  this is my valentines from  of my nephews i am...      1\n",
       "3   neutral/1000.jpg  betterfeelingfilms rt via instagram first day ...      0\n",
       "4  positive/1001.jpg               zoes first love rattled johnnyharper      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this block to define and process the MVSA dataframe again from the uploaded file\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Load MVSA labeled text\n",
    "mvsa_text_df = pd.read_excel(\"/Users/karthikviyyuri/Documents/finalmini/datasets/MVSA/LabeledText.xlsx\")\n",
    "\n",
    "# Convert .txt filenames to .jpg\n",
    "mvsa_text_df['image_file'] = mvsa_text_df['File Name'].apply(lambda x: x.replace('.txt', '.jpg'))\n",
    "\n",
    "# Normalize label text\n",
    "mvsa_text_df['label'] = mvsa_text_df['LABEL'].str.lower().map({\n",
    "    'negative': -1,\n",
    "    'neutral': 0,\n",
    "    'positive': 1\n",
    "})\n",
    "\n",
    "# Reconstruct image path from label\n",
    "def build_image_path(row):\n",
    "    label_map = {-1: \"negative\", 0: \"neutral\", 1: \"positive\"}\n",
    "    folder = label_map.get(row['label'])\n",
    "    if folder:\n",
    "        return os.path.join(folder, row['image_file'])\n",
    "    return None\n",
    "\n",
    "mvsa_text_df['image_path'] = mvsa_text_df.apply(build_image_path, axis=1)\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "mvsa_text_df['clean_text'] = mvsa_text_df['Caption'].apply(clean_text)\n",
    "\n",
    "# Show final result\n",
    "mvsa_text_df[['image_path', 'clean_text', 'label']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb962b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/karthikviyyuri/Documents/finalmini/data...</td>\n",
       "      <td>how i feel today legday jelly aching gym</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/karthikviyyuri/Documents/finalmini/data...</td>\n",
       "      <td>arrivatw absolute disgrace two carriages from ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/karthikviyyuri/Documents/finalmini/data...</td>\n",
       "      <td>this is my valentines from  of my nephews i am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/karthikviyyuri/Documents/finalmini/data...</td>\n",
       "      <td>betterfeelingfilms rt via instagram first day ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/karthikviyyuri/Documents/finalmini/data...</td>\n",
       "      <td>zoes first love rattled johnnyharper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  /Users/karthikviyyuri/Documents/finalmini/data...   \n",
       "1  /Users/karthikviyyuri/Documents/finalmini/data...   \n",
       "2  /Users/karthikviyyuri/Documents/finalmini/data...   \n",
       "3  /Users/karthikviyyuri/Documents/finalmini/data...   \n",
       "4  /Users/karthikviyyuri/Documents/finalmini/data...   \n",
       "\n",
       "                                          clean_text  label  \n",
       "0           how i feel today legday jelly aching gym     -1  \n",
       "1  arrivatw absolute disgrace two carriages from ...     -1  \n",
       "2  this is my valentines from  of my nephews i am...      1  \n",
       "3  betterfeelingfilms rt via instagram first day ...      0  \n",
       "4               zoes first love rattled johnnyharper      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define full base path for all categories\n",
    "base_image_dir = \"/Users/karthikviyyuri/Documents/finalmini/datasets/MVSA/Images\"\n",
    "\n",
    "# Replace relative image paths with full paths\n",
    "def build_full_image_path(row):\n",
    "    label_map = {-1: \"Negative\", 0: \"Neutral\", 1: \"Positive\"}  # use folder names as-is\n",
    "    folder = label_map.get(row['label'])\n",
    "    if folder:\n",
    "        return os.path.join(base_image_dir, folder, row['image_file'])\n",
    "    return None\n",
    "\n",
    "mvsa_text_df['image_path'] = mvsa_text_df.apply(build_full_image_path, axis=1)\n",
    "mvsa_text_df[['image_path', 'clean_text', 'label']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb753fc",
   "metadata": {},
   "source": [
    "## Step 2: Generate Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386a9f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8d9d01e463411e919aa8bf9e6788fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff69184a23f4394816ae7393dace767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20de3a924fdf430486c5aff67f42401f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6740a7991bcd4e1a8c7150b3bd0422be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef0d69249114b37a8d38eca0468dd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/555 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1107298bf5d044fe90166e95b7a2f725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cd10c9e02446f6badeaee201881ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/505 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02696c20263642f39a1e4cc35b4b419c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9931db7c464d5cb325d287a79e2edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3336edfc26bb4f4880aba7b05cc89545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bccc6b6c74b4e01bf3a4dca74eb106d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "text_model = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")\n",
    "\n",
    "mvsa_text_df['text_embedding'] = mvsa_text_df['clean_text'].apply(\n",
    "    lambda x: text_model.encode(x, normalize_embeddings=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c9e3a",
   "metadata": {},
   "source": [
    "## Step 3: Generate Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a79e8fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4869/4869 [05:52<00:00, 13.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load CLIP model\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model = clip_model.to(device)\n",
    "\n",
    "# Generate embeddings for all images\n",
    "def get_image_embedding(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.get_image_features(**inputs)\n",
    "        return (image_features[0] / image_features[0].norm()).cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply to dataset\n",
    "tqdm.pandas()\n",
    "mvsa_text_df['image_embedding'] = mvsa_text_df['image_path'].progress_apply(get_image_embedding)\n",
    "\n",
    "# Drop rows with failed image embeddings\n",
    "mvsa_text_df = mvsa_text_df.dropna(subset=['image_embedding'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf8211",
   "metadata": {},
   "source": [
    "## Step 4: Train Text and Image Sentiment Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30eeec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4869/4869 [00:55<00:00, 88.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4869/4869 [05:30<00:00, 14.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the embeddings if not already present in the current session\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load models\n",
    "text_model = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model = clip_model.to(device)\n",
    "\n",
    "# Text embeddings\n",
    "tqdm.pandas()\n",
    "mvsa_text_df['text_embedding'] = mvsa_text_df['clean_text'].progress_apply(lambda x: text_model.encode(x, normalize_embeddings=True))\n",
    "\n",
    "# Image embeddings\n",
    "def get_image_embedding(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.get_image_features(**inputs)\n",
    "        return (image_features[0] / image_features[0].norm()).cpu().numpy()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "mvsa_text_df['image_embedding'] = mvsa_text_df['image_path'].progress_apply(get_image_embedding)\n",
    "\n",
    "# Drop rows with missing embeddings\n",
    "mvsa_text_df = mvsa_text_df.dropna(subset=['text_embedding', 'image_embedding'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e73d132",
   "metadata": {},
   "source": [
    "## Step 5: Create Cache and FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b659c2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text index size: 4869\n",
      "Image index size: 4869\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Stack embeddings\n",
    "text_embeddings = np.stack(mvsa_text_df['text_embedding'].values)\n",
    "image_embeddings = np.stack(mvsa_text_df['image_embedding'].values)\n",
    "\n",
    "# Build indexes\n",
    "text_faiss_index = faiss.IndexFlatIP(text_embeddings.shape[1])\n",
    "image_faiss_index = faiss.IndexFlatIP(image_embeddings.shape[1])\n",
    "\n",
    "text_faiss_index.add(text_embeddings)\n",
    "image_faiss_index.add(image_embeddings)\n",
    "\n",
    "# Check total vectors added\n",
    "print(f\"Text index size: {text_faiss_index.ntotal}\")\n",
    "print(f\"Image index size: {image_faiss_index.ntotal}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19711dc6",
   "metadata": {},
   "source": [
    "##FALL BACK CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79c9c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train on BERT text embeddings\n",
    "X_text = np.stack(mvsa_text_df['text_embedding'].values)\n",
    "y = mvsa_text_df['label'].values\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X_text, y, stratify=y, test_size=0.2)\n",
    "\n",
    "text_clf = LogisticRegression(max_iter=1000).fit(X_text_train, y_train)\n",
    "\n",
    "# Train on CLIP image embeddings\n",
    "X_img = np.stack(mvsa_text_df['image_embedding'].values)\n",
    "img_clf = LogisticRegression(max_iter=1000).fit(X_img, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c346f",
   "metadata": {},
   "source": [
    "## Step 6: Prediction with Cache Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7da748ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_faiss(input_data, mode='text', threshold=0.90):\n",
    "    if mode == 'text':\n",
    "        emb = text_model.encode(input_data, normalize_embeddings=True)\n",
    "        D, I = text_faiss_index.search(np.array([emb]), k=1)\n",
    "        if D[0][0] > threshold:\n",
    "            return {\"sentiment\": int(mvsa_text_df.iloc[I[0][0]]['label']), \"source\": \"cache\"}\n",
    "        return {\"sentiment\": int(text_clf.predict([emb])[0]), \"source\": \"classifier\"}\n",
    "\n",
    "    elif mode == 'image':\n",
    "        emb = get_image_embedding(input_data)\n",
    "        D, I = image_faiss_index.search(np.array([emb]), k=1)\n",
    "        if D[0][0] > threshold:\n",
    "            return {\"sentiment\": int(mvsa_text_df.iloc[I[0][0]]['label']), \"source\": \"cache\"}\n",
    "        return {\"sentiment\": int(img_clf.predict([emb])[0]), \"source\": \"classifier\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c733d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6848049281314168,\n",
       " '              precision    recall  f1-score   support\\n\\n          -1      0.649     0.680     0.664       291\\n           0      0.662     0.599     0.629       354\\n           1      0.736     0.781     0.758       329\\n\\n    accuracy                          0.685       974\\n   macro avg      0.683     0.687     0.684       974\\nweighted avg      0.683     0.685     0.683       974\\n')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that embeddings are generated, let's proceed with training the MLP on fused features\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "text_embeddings = np.stack(mvsa_text_df['text_embedding'].values)\n",
    "image_embeddings = np.stack(mvsa_text_df['image_embedding'].values)\n",
    "labels = mvsa_text_df['label'].values\n",
    "\n",
    "# Multimodal fusion\n",
    "fused_embeddings = np.hstack((text_embeddings, image_embeddings))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(fused_embeddings, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Train MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), activation='relu', solver='adam', max_iter=300, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, digits=3)\n",
    "\n",
    "accuracy, report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1c7e0",
   "metadata": {},
   "source": [
    "## Step 7: EVALUATION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "912a48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_text = np.stack(mvsa_text_df['text_embedding'].values)\n",
    "X_image = np.stack(mvsa_text_df['image_embedding'].values)\n",
    "y = mvsa_text_df['label'].values\n",
    "\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_text, y, test_size=0.2, stratify=y)\n",
    "X_image_train, X_image_test, y_image_train, y_image_test = train_test_split(X_image, y, test_size=0.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df7c3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "text_clf = LogisticRegression(max_iter=1000).fit(X_text_train, y_text_train)\n",
    "image_clf = LogisticRegression(max_iter=1000).fit(X_image_train, y_image_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e381b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Text Classifier Metrics (BERT):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1      0.631     0.639     0.635       291\n",
      "           0      0.628     0.582     0.604       354\n",
      "           1      0.749     0.799     0.774       329\n",
      "\n",
      "    accuracy                          0.672       974\n",
      "   macro avg      0.669     0.673     0.671       974\n",
      "weighted avg      0.670     0.672     0.671       974\n",
      "\n",
      "Confusion Matrix (Text):\n",
      "[[186  76  29]\n",
      " [ 89 206  59]\n",
      " [ 20  46 263]]\n",
      "\n",
      "üñºÔ∏è Image Classifier Metrics (CLIP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1      0.457     0.416     0.435       291\n",
      "           0      0.432     0.452     0.442       354\n",
      "           1      0.469     0.483     0.476       329\n",
      "\n",
      "    accuracy                          0.452       974\n",
      "   macro avg      0.453     0.450     0.451       974\n",
      "weighted avg      0.452     0.452     0.451       974\n",
      "\n",
      "Confusion Matrix (Image):\n",
      "[[121 102  68]\n",
      " [ 82 160 112]\n",
      " [ 62 108 159]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# TEXT Classifier Evaluation\n",
    "y_text_pred = text_clf.predict(X_text_test)\n",
    "print(\"üìò Text Classifier Metrics (BERT):\")\n",
    "print(classification_report(y_text_test, y_text_pred, digits=3))\n",
    "print(\"Confusion Matrix (Text):\")\n",
    "print(confusion_matrix(y_text_test, y_text_pred))\n",
    "\n",
    "# IMAGE Classifier Evaluation\n",
    "y_image_pred = image_clf.predict(X_image_test)\n",
    "print(\"\\nüñºÔ∏è Image Classifier Metrics (CLIP):\")\n",
    "print(classification_report(y_image_test, y_image_pred, digits=3))\n",
    "print(\"Confusion Matrix (Image):\")\n",
    "print(confusion_matrix(y_image_test, y_image_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba42246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4869/4869 [00:54<00:00, 89.01it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4869/4869 [06:43<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1      0.633     0.646     0.639       291\n",
      "           0      0.639     0.585     0.611       354\n",
      "           1      0.734     0.787     0.760       329\n",
      "\n",
      "    accuracy                          0.671       974\n",
      "   macro avg      0.669     0.673     0.670       974\n",
      "weighted avg      0.669     0.671     0.670       974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 2. Load models\n",
    "text_model = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model = clip_model.to(device)\n",
    "\n",
    "# 3. Embedding functions\n",
    "def get_image_embedding(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.get_image_features(**inputs)\n",
    "        return (image_features[0] / image_features[0].norm()).cpu().numpy()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "# 4. Load + Clean Data\n",
    "df = pd.read_excel(\"/Users/karthikviyyuri/Documents/finalmini/datasets/MVSA/LabeledText.xlsx\")\n",
    "df = df.dropna(subset=[\"Caption\", \"LABEL\"])\n",
    "df[\"label\"] = df[\"LABEL\"].str.lower().map({\"negative\": -1, \"neutral\": 0, \"positive\": 1})\n",
    "df[\"clean_text\"] = df[\"Caption\"].apply(clean_text)\n",
    "df[\"image_file\"] = df[\"File Name\"].apply(lambda x: x.replace(\".txt\", \".jpg\"))\n",
    "df[\"image_path\"] = df.apply(lambda r: f\"/Users/karthikviyyuri/Documents/finalmini/datasets/MVSA/Images/{['Negative','Neutral','Positive'][r.label+1]}/{r.image_file}\", axis=1)\n",
    "\n",
    "# 5. Generate embeddings\n",
    "tqdm.pandas()\n",
    "df[\"text_embedding\"] = df[\"clean_text\"].progress_apply(lambda x: text_model.encode(x, normalize_embeddings=True))\n",
    "df[\"image_embedding\"] = df[\"image_path\"].progress_apply(get_image_embedding)\n",
    "df = df.dropna(subset=[\"text_embedding\", \"image_embedding\"])\n",
    "\n",
    "# 6. Train Multimodal MLP Classifier\n",
    "X = np.hstack([np.stack(df[\"text_embedding\"]), np.stack(df[\"image_embedding\"])])\n",
    "y = df[\"label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 128), activation='relu', max_iter=300)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402692c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
